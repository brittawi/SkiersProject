{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatgpt Code for splitting mp4 video to jpg for AlphaPose halpe fine tuning\n",
    "import cv2\n",
    "\n",
    "read_path = \"E:\\\\SkiProject\\\\Original_videos\\\\DJI_0044.MP4\"\n",
    "save_path = \"E:\\\\SkiProject\\\\Frames_of_videos\\\\DJI_0044\\\\\"\n",
    "vidcap = cv2.VideoCapture(read_path)\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    cv2.imwrite(f\"{save_path}frame_{count:06d}.jpg\", image)     # Save frame as JPEG file\n",
    "    success, image = vidcap.read()\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatgpt code for replacing png woth jpg in CVAT annotation file\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Update file names in the \"images\" section to change .PNG to .jpg\n",
    "for image in data.get(\"images\", []):\n",
    "    image[\"file_name\"] = image[\"file_name\"].replace(\".PNG\", \".jpg\")\n",
    "\n",
    "# Save the updated JSON file\n",
    "updated_file_path = 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated.json'\n",
    "with open(updated_file_path, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated_train.json',\n",
       " 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated_val.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# File paths (reloading after reset)\n",
    "json_file_path = 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated.json'\n",
    "images_folder = \"E:\\\\SkiProject\\\\Frames_of_videos\\\\DJI_0044\\\\\"  # Assuming images are in this folder\n",
    "train_folder = \"E:\\\\SkiProject\\\\Frames_of_videos\\\\DJI_0044\\\\train\\\\\"\n",
    "val_folder = \"E:\\\\SkiProject\\\\Frames_of_videos\\\\DJI_0044\\\\val\\\\\"\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create train and validation folders\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "\n",
    "# Shuffle and split the images (80% train, 20% validation)\n",
    "images = data[\"images\"]\n",
    "random.shuffle(images)\n",
    "split_index = int(0.8 * len(images))\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]\n",
    "\n",
    "# Helper function to move images\n",
    "def move_images(image_list, dest_folder):\n",
    "    for image in image_list:\n",
    "        image_name = image['file_name']\n",
    "        src_path = os.path.join(images_folder, image_name)\n",
    "        dest_path = os.path.join(dest_folder, image_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Move train and validation images to their respective folders\n",
    "move_images(train_images, train_folder)\n",
    "move_images(val_images, val_folder)\n",
    "\n",
    "# Filter annotations for train and validation\n",
    "train_image_ids = {img[\"id\"] for img in train_images}\n",
    "val_image_ids = {img[\"id\"] for img in val_images}\n",
    "\n",
    "train_annotations = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] in train_image_ids]\n",
    "val_annotations = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] in val_image_ids]\n",
    "\n",
    "# Create new train and validation JSON files\n",
    "train_data = {\n",
    "    \"info\": data[\"info\"],\n",
    "    \"licenses\": data[\"licenses\"],\n",
    "    \"categories\": data[\"categories\"],\n",
    "    \"images\": train_images,\n",
    "    \"annotations\": train_annotations\n",
    "}\n",
    "\n",
    "val_data = {\n",
    "    \"info\": data[\"info\"],\n",
    "    \"licenses\": data[\"licenses\"],\n",
    "    \"categories\": data[\"categories\"],\n",
    "    \"images\": val_images,\n",
    "    \"annotations\": val_annotations\n",
    "}\n",
    "\n",
    "# Save the train and validation JSON files\n",
    "train_json_path = 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated_train.json'\n",
    "val_json_path = 'E:\\\\SkiProject\\\\annotations_test_DJI_0044\\\\person_keypoints_default_updated_val.json'\n",
    "\n",
    "with open(train_json_path, 'w') as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "\n",
    "with open(val_json_path, 'w') as f:\n",
    "    json.dump(val_data, f, indent=4)\n",
    "\n",
    "train_json_path, val_json_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ski_project_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
