{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/open-mmlab/mmpose/blob/main/docs/en/user_guides/inference.md\n",
    "\n",
    "The inferencer is capable of processing a range of input types, which includes the following:\n",
    "\n",
    "A path to an image\n",
    "A path to a video\n",
    "A path to a folder (which will cause all images in that folder to be inferred)\n",
    "An image array (NA for CLI tool)\n",
    "A list of image arrays (NA for CLI tool)\n",
    "A webcam (in which case the input parameter should be set to either 'webcam' or 'webcam:{CAMERA_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "\n",
    "print('torch version:', torch.__version__, torch.cuda.is_available(), torch.backends.mps.is_available())\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "\n",
    "# Check MMPose installation\n",
    "import mmpose\n",
    "\n",
    "print('mmpose version:', mmpose.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "\n",
    "print('cuda version:', get_compiling_cuda_version())\n",
    "print('compiler information:', get_compiler_version())\n",
    "\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\"\n",
    "RESULT_PATH = \"./resultsMMPose/video_output\"\n",
    "PATH_ANNO = RESULT_PATH + \"/predictions\"\n",
    "\n",
    "video_files = glob.glob(PATH + \"\\\\*.mp4\")\n",
    "print(len(video_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use MMPose Inferencer to predict keypoints for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Can't use MPS not implemented\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# instantiate the inferencer using the model alias\n",
    "inferencer = MMPoseInferencer('human', device=device)\n",
    "\n",
    "for video_path in video_files:\n",
    "\n",
    "    # The MMPoseInferencer API employs a lazy inference approach,\n",
    "    # creating a prediction generator when given input\n",
    "    result_generator = inferencer(video_path, show=True, out_dir=RESULT_PATH)\n",
    "    results = [result for result in result_generator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Annotations in Coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert json file that we get out of MMPose into Coco format\n",
    "# only use keypoints where the average score is over 50 %\n",
    "def convert_to_coco_format(input_file, output_file, score_threshold=0.5):\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    coco_format = {\n",
    "        \"info\": {\n",
    "            \"description\": \"Skiers dataset\",\n",
    "            \"url\": \"\",  # Add a relevant link if available\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": datetime.now().year,\n",
    "            \"contributor\": \"LTU\",\n",
    "            \"date_created\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 0,\n",
    "                \"name\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # Define categories (e.g., \"person\")\n",
    "    category_id = 1\n",
    "    coco_format[\"categories\"].append({\n",
    "        \"id\": category_id,\n",
    "        \"name\": \"body\",\n",
    "        \"supercategory\": \"\",\n",
    "        \"keypoints\": [\n",
    "            \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\"\n",
    "        ],\n",
    "        \"skeleton\": [\n",
    "            [1,12],[1,2],[10,8],[13,1],[6,1],[15,13],[4,2],[14,16],[7,9],[12,14],[1,7],[8,6],[17,15],[9,11],[1,3],[3,5]\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    annotation_id = 1\n",
    "    for frame in data:\n",
    "        frame_id = frame[\"frame_id\"]\n",
    "\n",
    "        # Add image info\n",
    "        coco_format[\"images\"].append({\n",
    "            \"id\": frame_id,\n",
    "            \"file_name\": f\"frame_{frame_id:06d}.png\",\n",
    "            \"width\": 1920,  # Update with your video resolution\n",
    "            \"height\": 1080,  # Update with your video resolution\n",
    "            \"license\" : 0,\n",
    "            \"flickr_url\" : \"\",\n",
    "            \"coco_url\" : \"\",\n",
    "            \"date_captured\" : 0\n",
    "        })\n",
    "\n",
    "        for instance in frame[\"instances\"]:\n",
    "            scores = instance.get(\"keypoint_scores\", [])\n",
    "            if len(scores) == 0 or sum(scores) / len(scores) < score_threshold:\n",
    "                # Skip keypoints for this instance if average score is below threshold\n",
    "                continue\n",
    "            \n",
    "            keypoints = []\n",
    "            bbox = instance.get(\"bbox\", [[0, 0, 0, 0]])[0]  # Assuming single bbox per instance\n",
    "\n",
    "            # Flatten keypoints into COCO format [x1, y1, v1, x2, y2, v2, ...]\n",
    "            for i, (x, y) in enumerate(instance[\"keypoints\"]):\n",
    "                v = 1 if scores[i] > 0 else 0  # Visibility based on score (visible or not)\n",
    "                keypoints.extend([x, y, v])\n",
    "\n",
    "            # Add annotation\n",
    "            coco_format[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": frame_id,\n",
    "                \"category_id\": category_id,\n",
    "                \"bbox\": [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],  # x, y, width, height\n",
    "                \"area\": (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                \"keypoints\": keypoints,\n",
    "                \"num_keypoints\": sum([1 for v in keypoints[2::3] if v > 0]),\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": [] \n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "    # Write to output file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_format, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_FOLDER = \"/Users/emillundin/Desktop/Ski_project/output_coco_format\"\n",
    "# create folder if it does not exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "   os.makedirs(OUTPUT_FOLDER)\n",
    "   \n",
    "annotation_files = glob.glob(PATH_ANNO + \"/*.json\")\n",
    "print(len(annotation_files))\n",
    "\n",
    "for anno in annotation_files:\n",
    "    filename = os.path.basename(anno).split(\".\")[0] + \"_coco.json\"\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "    convert_to_coco_format(anno, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create skeleton gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Function to extract keypoints from JSON\n",
    "def get_keypoints(frame_index, data):\n",
    "    annotation = data['annotations'][frame_index]\n",
    "    keypoints = annotation['keypoints']\n",
    "    keypoints_xy = [\n",
    "        (1920 - keypoints[i], 1080 - keypoints[i + 1])  # Reverse the coordinates for your format\n",
    "        for i in range(0, len(keypoints), 3)\n",
    "    ]\n",
    "    return keypoints_xy\n",
    "\n",
    "# Function to plot a single skeleton frame\n",
    "def plot_skeleton_frame(keypoints_xy, skeleton, save_path, frame_index):\n",
    "    x_coords = [kp[0] for kp in keypoints_xy]\n",
    "    y_coords = [kp[1] for kp in keypoints_xy]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x_coords, y_coords, color='red')\n",
    "\n",
    "    # Draw lines for the skeleton\n",
    "    for start, end in skeleton:\n",
    "        start_point = (x_coords[start], y_coords[start])\n",
    "        end_point = (x_coords[end], y_coords[end])\n",
    "        ax.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 'k-', lw=2)\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(f'Skeleton Frame {frame_index}')\n",
    "\n",
    "    # Save the frame\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Generate frames and save them as images\n",
    "def generate_frames(starting_time,\n",
    "                    ending_time, \n",
    "                    temp_folder_path, \n",
    "                    data, \n",
    "                    skeleton):\n",
    "    \n",
    "    os.makedirs(temp_folder_path, exist_ok=True)\n",
    "    \n",
    "    frame_indices = range(starting_time, ending_time, 1) \n",
    "    image_paths = []\n",
    "    for i, frame_index in enumerate(frame_indices):\n",
    "        keypoints_xy = get_keypoints(frame_index, data)\n",
    "        image_path = temp_folder_path + f\"/frame_{i}.png\"\n",
    "        plot_skeleton_frame(keypoints_xy, skeleton, image_path, frame_index)\n",
    "        image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def create_skeleton_gif(coco_json_path, \n",
    "                        skeleton,\n",
    "                        starting_frame,\n",
    "                        ending_frame,\n",
    "                        temp_folder_path,\n",
    "                        frames_per_second,\n",
    "                        gif_file_path,\n",
    "                        remove_frame_folder = False\n",
    "                        ):\n",
    "    # Load the JSON file\n",
    "    with open(coco_json_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    image_paths = generate_frames(starting_frame, ending_frame, temp_folder_path, data, skeleton)\n",
    "    # Compile the frames into a GIF\n",
    "    frames = [Image.open(img) for img in image_paths]\n",
    "    frames[0].save(gif_file_path, save_all=True, append_images=frames[1:], duration=1000/frames_per_second, loop=0)\n",
    "    if remove_frame_folder:\n",
    "        shutil.rmtree(temp_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_json_path = '/Users/emillundin/Desktop/Ski_project/output_coco_format/DJI_0001_coco.json'\n",
    "# keypoints connections to create the skeleton\n",
    "skeleton =  [\n",
    "            [1,12],[1,2],[10,8],[13,1],[6,1],[15,13],[4,2],[14,16],[7,9],[12,14],[1,7],[8,6],[17,15],[9,11],[1,3],[3,5],\n",
    "            [6,12], [12,13], [7, 13] # additional for more coherent lines\n",
    "        ]\n",
    "skeleton = [[x - 1, y - 1] for x, y in skeleton] # Convert skeleton from 1-based indexing to 0-based\n",
    "starting_time = 26 # in seconds\n",
    "ending_time = 32 # in seconds\n",
    "frames_per_second = 30 # change depending on video frames per second\n",
    "gif_frames_per_second = 15 # frames per second of the output gif\n",
    "starting_frame = starting_time*frames_per_second\n",
    "ending_frame = ending_time*frames_per_second\n",
    "temp_folder_path = \"skeleton_images\"\n",
    "gif_file_path = 'skeleton_animation.gif'\n",
    "\n",
    "create_skeleton_gif(coco_json_path, \n",
    "                    skeleton,\n",
    "                    starting_frame,\n",
    "                    ending_frame,\n",
    "                    temp_folder_path,\n",
    "                    gif_frames_per_second,\n",
    "                    gif_file_path,\n",
    "                    remove_frame_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
