{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat GPT code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing videos and output directories\n",
    "# Specify the folder where the videos are in\n",
    "video_folder = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\annotated_videos\\\\\"\n",
    "# Specify a folder where frames of videos can be saved in temporarily\n",
    "output_frame_path = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Frames_of_videos\\\\\" \n",
    "# Specify the folder where the annotations are in that belong to the  videos\n",
    "annotation_folder = \"C:\\\\awilde\\\\britta\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Annotations\\\\manual_annotations\\\\\" \n",
    "\n",
    "# Output folders for train, validation and test data\n",
    "train_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images\\\\train2015\"\n",
    "val_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images\\\\val2017\"\n",
    "test_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images\\\\test\"\n",
    "train_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations\\\\combined_train_annotations.json\"\n",
    "val_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations\\\\combined_val_annotations.json\"\n",
    "test_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations\\\\combined_test_annotations.json\"\n",
    "\n",
    "train_size = 0.72\n",
    "val_size = 0.18\n",
    "test_size = 0.1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Maximum frame limits for specific videos (optional)\n",
    "frame_limits = {\n",
    "    \"DJI_0009.MP4\": 890\n",
    "}\n",
    "\n",
    "# Initialize counters\n",
    "frame_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the corresponding JSON filename\n",
    "def get_json_filename(video_name):\n",
    "    match = re.search(r'DJI_0*(\\d+)(_cut)?', video_name)\n",
    "    if match:\n",
    "        number = match.group(1).zfill(2)  # Extract the numeric part\n",
    "        suffix = match.group(2) if match.group(2) else \"\"  # Extract '_cut' if present\n",
    "        return f\"{number}{suffix}.json\"\n",
    "    return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9532\n",
      "2383\n",
      "Train size 9532, val 2383, test 1325\n",
      "Processed 13240 frames in total.\n",
      "Train: 9532 images, 9532 annotations\n",
      "Validation: 2383 images, 2383 annotations\n",
      "Test: 1325 images, 1325 annotations\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directories exist\n",
    "os.makedirs(train_output_folder, exist_ok=True)\n",
    "os.makedirs(val_output_folder, exist_ok=True)\n",
    "os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "image_id_counter = 1  # Start image IDs at 1\n",
    "annotation_id_counter = 1  # Start annotation IDs at 1\n",
    "frame_counter = 0  # Initialize frame counter\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.MP4'))]\n",
    "\n",
    "all_images = []\n",
    "all_annotations = []\n",
    "categories = []\n",
    "\n",
    "# Process each video and corresponding JSON\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    json_file_name = get_json_filename(video_file)\n",
    "    json_path = os.path.join(annotation_folder, json_file_name)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Warning: JSON file {json_file_name} not found for {video_file}. Path: {json_path} Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Split video into frames\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    current_frame = 0\n",
    "    max_frames = frame_limits.get(video_file, float('inf'))  # Default to no limit\n",
    "\n",
    "    while success and current_frame <= max_frames:\n",
    "        frame_name = f\"frame_{frame_counter:06d}.jpg\"\n",
    "        \n",
    "        # Temporarily save path (actual folder will be assigned after splitting)\n",
    "        save_path = os.path.join(output_frame_path, frame_name)\n",
    "        cv2.imwrite(save_path, image)\n",
    "\n",
    "        # Store image metadata\n",
    "        all_images.append({\n",
    "            \"id\": image_id_counter,\n",
    "            \"width\": image.shape[1],\n",
    "            \"height\": image.shape[0],\n",
    "            \"file_name\": frame_name,\n",
    "            \"license\": 0,\n",
    "            \"flickr_url\": \"\",\n",
    "            \"coco_url\": \"\",\n",
    "            \"date_captured\": 0\n",
    "        })\n",
    "\n",
    "        success, image = vidcap.read()\n",
    "        frame_counter += 1\n",
    "        image_id_counter += 1\n",
    "        current_frame += 1\n",
    "\n",
    "    # Load JSON annotations\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        annotation[\"id\"] = annotation_id_counter\n",
    "        annotation[\"image_id\"] = annotation_id_counter  # Align with the correct frame ID\n",
    "        all_annotations.append(annotation)\n",
    "        annotation_id_counter += 1\n",
    "\n",
    "    # Add categories once\n",
    "    if not categories:\n",
    "        categories = data.get(\"categories\", [])\n",
    "\n",
    "# Shuffle images and annotations\n",
    "combined = list(zip(all_images, all_annotations))\n",
    "random.seed(seed)\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Split the data\n",
    "split_idx_train = int(len(combined) * train_size)\n",
    "split_idx_val = int(len(combined) * val_size)\n",
    "train_data = combined[:split_idx_train]\n",
    "val_data = combined[split_idx_train:split_idx_train+split_idx_val]\n",
    "test_data = combined[split_idx_train+split_idx_val:]\n",
    "\n",
    "# Separate images and annotations after splitting\n",
    "train_images, train_annotations = zip(*train_data)\n",
    "val_images, val_annotations = zip(*val_data)\n",
    "test_images, test_annotations = zip(*test_data)\n",
    "\n",
    "# Move images to respective train/val folders\n",
    "for img in train_images:\n",
    "    src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "    dest_path = os.path.join(train_output_folder, img[\"file_name\"])\n",
    "    shutil.move(src_path, dest_path)  # Move image to train folder\n",
    "\n",
    "for img in val_images:\n",
    "    src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "    dest_path = os.path.join(val_output_folder, img[\"file_name\"])\n",
    "    shutil.move(src_path, dest_path)  # Move image to validation folder\n",
    "    \n",
    "for img in test_images:\n",
    "    src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "    dest_path = os.path.join(test_output_folder, img[\"file_name\"])\n",
    "    shutil.move(src_path, dest_path)  # Move image to validation folder\n",
    "\n",
    "# Create COCO-style JSONs for train and validation\n",
    "train_json = {\n",
    "    \"licenses\": [],\n",
    "    \"info\": [],\n",
    "    \"images\": list(train_images),\n",
    "    \"annotations\": list(train_annotations),\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "val_json = {\n",
    "    \"licenses\": [],\n",
    "    \"info\": [],\n",
    "    \"images\": list(val_images),\n",
    "    \"annotations\": list(val_annotations),\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "test_json = {\n",
    "    \"licenses\": [],\n",
    "    \"info\": [],\n",
    "    \"images\": list(test_images),\n",
    "    \"annotations\": list(test_annotations),\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "# Save train and validation JSON files\n",
    "with open(train_annotation_combined, 'w+') as f:\n",
    "    json.dump(train_json, f, indent=4)\n",
    "\n",
    "with open(val_annotation_combined, 'w+') as f:\n",
    "    json.dump(val_json, f, indent=4)\n",
    "    \n",
    "with open(test_annotation_combined, 'w+') as f:\n",
    "    json.dump(test_json, f, indent=4)\n",
    "\n",
    "print(f\"Processed {frame_counter} frames in total.\")\n",
    "print(f\"Train: {len(train_images)} images, {len(train_annotations)} annotations\")\n",
    "print(f\"Validation: {len(val_images)} images, {len(val_annotations)} annotations\")\n",
    "print(f\"Test: {len(test_images)} images, {len(test_annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_id_counter = 1  # Start image IDs at 1\n",
    "# annotation_id_counter = 1  # Start annotation IDs at 1\n",
    "\n",
    "# video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.MP4'))]\n",
    "\n",
    "# # Process each video and corresponding JSON\n",
    "# for video_file in video_files:\n",
    "#     video_path = os.path.join(video_folder, video_file)\n",
    "#     json_file_name = get_json_filename(video_file)\n",
    "#     print(json_file_name)\n",
    "#     #json_path = os.path.join(annotation_folder, f\"{os.path.splitext(video_file)[0]}_annotations.json\")\n",
    "#     json_path = os.path.join(annotation_folder, json_file_name)\n",
    "#     print(json_path)\n",
    "\n",
    "#     # Check if the JSON file exists\n",
    "#     if not os.path.exists(json_path):\n",
    "#         print(f\"Warning: JSON file not found for {video_file}. Skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     # Split video into frames\n",
    "#     vidcap = cv2.VideoCapture(video_path)\n",
    "#     success, image = vidcap.read()\n",
    "#     current_frame = 0\n",
    "#     max_frames = frame_limits.get(video_file, float('inf'))  # Default to no limit if not specified\n",
    "\n",
    "#     while success and current_frame <= max_frames:\n",
    "#         # Save frame with sequential numbering based on global frame_counter\n",
    "#         frame_name = f\"frame_{frame_counter:06d}.jpg\"\n",
    "#         save_path = os.path.join(output_frame_path, frame_name)\n",
    "#         cv2.imwrite(save_path, image)\n",
    "\n",
    "#         # Add to combined JSON\n",
    "#         combined_data[\"images\"].append({\n",
    "#             \"id\": image_id_counter,\n",
    "#             \"width\": image.shape[1],\n",
    "#             \"height\": image.shape[0],\n",
    "#             \"file_name\": frame_name,\n",
    "#             \"license\": 0,\n",
    "#             \"flickr_url\": \"\",\n",
    "#             \"coco_url\": \"\",\n",
    "#             \"date_captured\": 0\n",
    "#         })\n",
    "\n",
    "#         success, image = vidcap.read()\n",
    "#         frame_counter += 1\n",
    "#         image_id_counter += 1  # Increment image ID counter\n",
    "#         current_frame += 1\n",
    "\n",
    "#     # Update JSON file\n",
    "#     with open(json_path, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     for annotation in data.get(\"annotations\", []):\n",
    "#         # Assign a sequential ID and link to the correct image\n",
    "#         annotation[\"id\"] = annotation_id_counter\n",
    "#         annotation[\"image_id\"] = annotation_id_counter  # Align with the correct frame ID\n",
    "#         combined_data[\"annotations\"].append(annotation)\n",
    "#         annotation_id_counter += 1\n",
    "\n",
    "#     # Add categories only once (assumes they are consistent across files)\n",
    "#     if not combined_data[\"categories\"]:\n",
    "#         combined_data[\"categories\"] = data.get(\"categories\", [])\n",
    "\n",
    "# # Save the combined JSON\n",
    "# with open(combined_json_path, 'w') as f:\n",
    "#     json.dump(combined_data, f, indent=4)\n",
    "\n",
    "# print(f\"Processed {frame_counter} frames in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import cv2\n",
    "\n",
    "# # Draw annotations on a frame\n",
    "# def draw_annotations(frame, annotations, categories):\n",
    "#     for ann in annotations:\n",
    "#         keypoints = ann.get(\"keypoints\", [])\n",
    "#         category_id = ann.get(\"category_id\", None)\n",
    "#         category_name = next((cat[\"name\"] for cat in categories if cat[\"id\"] == category_id), \"unknown\")\n",
    "        \n",
    "#         # Draw keypoints\n",
    "#         for i in range(0, len(keypoints), 3):\n",
    "#             x, y, v = keypoints[i:i+3]  # x, y, visibility\n",
    "#             if v > 0:  # Only draw visible keypoints\n",
    "#                 cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)  # Green keypoints\n",
    "\n",
    "#         # Optionally, draw lines (skeleton) if available\n",
    "#         skeleton = categories[0].get(\"skeleton\", [])\n",
    "#         for connection in skeleton:\n",
    "#             start_idx, end_idx = connection\n",
    "#             if start_idx < len(keypoints) // 3 and end_idx < len(keypoints) // 3:\n",
    "#                 x1, y1, v1 = keypoints[start_idx * 3:start_idx * 3 + 3]\n",
    "#                 x2, y2, v2 = keypoints[end_idx * 3:end_idx * 3 + 3]\n",
    "#                 if v1 > 0 and v2 > 0:  # Only draw lines between visible points\n",
    "#                     cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)  # Blue lines\n",
    "\n",
    "#     return frame\n",
    "\n",
    "# # Verify frames by drawing annotations\n",
    "# def verify_frames_with_annotations(images, annotations, frame_path, categories, num_verifications=5):\n",
    "#     print(\"\\n--- Verifying Frames with Annotations ---\")\n",
    "#     for _ in range(num_verifications):\n",
    "#         # Pick a random image\n",
    "#         image = random.choice(images)\n",
    "#         frame_file = os.path.join(frame_path, image[\"file_name\"])\n",
    "\n",
    "#         # Find associated annotations\n",
    "#         associated_annotations = [ann for ann in annotations if ann[\"image_id\"] == image[\"id\"]]\n",
    "\n",
    "#         print(f\"Verifying Frame: {image['file_name']}, ID: {image['id']}\")\n",
    "#         print(\"Annotations:\")\n",
    "#         for ann in associated_annotations:\n",
    "#             print(f\"  - ID: {ann['id']}, Keypoints: {ann['keypoints']}\")\n",
    "\n",
    "#         # Load and annotate the frame\n",
    "#         frame = cv2.imread(frame_file)\n",
    "#         if frame is not None:\n",
    "#             annotated_frame = draw_annotations(frame, associated_annotations, categories)\n",
    "\n",
    "#             # Display the annotated frame\n",
    "#             cv2.imshow(f\"Frame {image['id']} with Annotations\", annotated_frame)\n",
    "#             cv2.waitKey(0)  # Press any key to close the frame window\n",
    "#             cv2.destroyAllWindows()\n",
    "#         else:\n",
    "#             print(f\"Warning: Unable to load frame {frame_file}\")\n",
    "\n",
    "# # Call verification after processing all videos\n",
    "# verify_frames_with_annotations(\n",
    "#     combined_data[\"images\"], \n",
    "#     combined_data[\"annotations\"], \n",
    "#     output_frame_path, \n",
    "#     combined_data[\"categories\"]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
