{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split annotated videos into train, validation and test set\n",
    "This code will split annotated videos into folders for training, validation and testing. To do so it will convert the videos into frames and create a single annotation files containing all annotations for each single frame. Based on the frames the data will then first be shuffled and moved to corresponding folders. The annotation files need to be in coco format. If downloaded from CVAT use COCO Keypoints 1.0 for exporting the keypoints. \n",
    "\n",
    "To run this you need to specify the following:\n",
    "- video_folder: folder that contains videos\n",
    "- annotation_folder: folder that contains corresponding annotations that should be marked with the same id\n",
    "- output_frame_path: here the frames will just be saved temporarily before being distributed into the different folders\n",
    "- train_output_folder\n",
    "- val_output_folder\n",
    "- test_output_folder\n",
    "- train_annotation_combined: file path where combined train annotations will be saved\n",
    "- val_annotation_combined\n",
    "- test_annotation_combined\n",
    "- train, val and test size\n",
    "- only_test: set this to True if you only want to convert the test data for example into single frames and a combined annotation file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing videos and output directories\n",
    "# Specify the folder where the videos are in\n",
    "video_folder = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\annotated_videos\\\\\"\n",
    "# Specify a folder where frames of videos can be saved in temporarily\n",
    "output_frame_path = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Frames_of_videos\\\\\" \n",
    "# Specify the folder where the annotations are in that belong to the  videos\n",
    "annotation_folder = \"C:\\\\awilde\\\\britta\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Annotations\\\\manual_annotations\\\\\" \n",
    "\n",
    "# Output folders for train, validation and test data\n",
    "train_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images2\\\\train2015\"\n",
    "val_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images2\\\\val2017\"\n",
    "test_output_folder = \"..\\\\alphapose\\\\data\\\\\\halpe\\\\images2\\\\test\"\n",
    "train_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations2\\\\combined_train_annotations.json\"\n",
    "val_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations2\\\\combined_val_annotations.json\"\n",
    "test_annotation_combined = \"..\\\\alphapose\\\\data\\\\halpe\\\\annotations2\\\\combined_test_annotations.json\"\n",
    "\n",
    "if only_test:\n",
    "    train_size = 0\n",
    "    val_size = 0\n",
    "    test_size = 1\n",
    "else:\n",
    "    train_size = 0.72\n",
    "    val_size = 0.18\n",
    "    test_size = 0.1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Maximum frame limits for specific videos (optional)\n",
    "frame_limits = {\n",
    "    #\"DJI_0009.MP4\": 890\n",
    "}\n",
    "\n",
    "# Initialize counters\n",
    "frame_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the corresponding JSON filename\n",
    "def get_json_filename(video_name):\n",
    "    match = re.search(r'DJI_0*(\\d+)(_cut)?', video_name)\n",
    "    if match:\n",
    "        number = match.group(1).zfill(2)  # Extract the numeric part\n",
    "        suffix = match.group(2) if match.group(2) else \"\"  # Extract '_cut' if present\n",
    "        return f\"{number}{suffix}.json\"\n",
    "    return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 208 frames in total.\n",
      "Test: 208 images, 208 annotations\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directories exist\n",
    "if only_test:\n",
    "    os.makedirs(test_output_folder, exist_ok=True)\n",
    "else: \n",
    "    os.makedirs(train_output_folder, exist_ok=True)\n",
    "    os.makedirs(val_output_folder, exist_ok=True)\n",
    "    os.makedirs(test_output_folder, exist_ok=True)\n",
    "\n",
    "image_id_counter = 1  # Start image IDs at 1\n",
    "annotation_id_counter = 1  # Start annotation IDs at 1\n",
    "frame_counter = 0  # Initialize frame counter\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.MP4'))]\n",
    "\n",
    "all_images = []\n",
    "all_annotations = []\n",
    "categories = []\n",
    "\n",
    "# Process each video and corresponding JSON\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    json_file_name = get_json_filename(video_file)\n",
    "    json_path = os.path.join(annotation_folder, json_file_name)\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Warning: JSON file {json_file_name} not found for {video_file}. Path: {json_path} Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Split video into frames\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    current_frame = 0\n",
    "    max_frames = frame_limits.get(video_file, float('inf'))  # Default to no limit\n",
    "\n",
    "    while success and current_frame <= max_frames:\n",
    "        frame_name = f\"frame_{frame_counter:06d}.jpg\"\n",
    "        \n",
    "        # Temporarily save path (actual folder will be assigned after splitting)\n",
    "        save_path = os.path.join(output_frame_path, frame_name)\n",
    "        cv2.imwrite(save_path, image)\n",
    "\n",
    "        # Store image metadata\n",
    "        all_images.append({\n",
    "            \"id\": image_id_counter,\n",
    "            \"width\": image.shape[1],\n",
    "            \"height\": image.shape[0],\n",
    "            \"file_name\": frame_name,\n",
    "            \"license\": 0,\n",
    "            \"flickr_url\": \"\",\n",
    "            \"coco_url\": \"\",\n",
    "            \"date_captured\": 0\n",
    "        })\n",
    "\n",
    "        success, image = vidcap.read()\n",
    "        frame_counter += 1\n",
    "        image_id_counter += 1\n",
    "        current_frame += 1\n",
    "\n",
    "    # Load JSON annotations\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        annotation[\"id\"] = annotation_id_counter\n",
    "        annotation[\"image_id\"] = annotation_id_counter  # Align with the correct frame ID\n",
    "        all_annotations.append(annotation)\n",
    "        annotation_id_counter += 1\n",
    "\n",
    "    # Add categories once\n",
    "    if not categories:\n",
    "        categories = data.get(\"categories\", [])\n",
    "\n",
    "# Shuffle images and annotations\n",
    "combined = list(zip(all_images, all_annotations))\n",
    "if only_test:\n",
    "    test_images, test_annotations = zip(*combined)\n",
    "else:\n",
    "    random.seed(seed)\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    # Split the data\n",
    "    split_idx_train = int(len(combined) * train_size)\n",
    "    split_idx_val = int(len(combined) * val_size)\n",
    "    train_data = combined[:split_idx_train]\n",
    "    val_data = combined[split_idx_train:split_idx_train+split_idx_val]\n",
    "    test_data = combined[split_idx_train+split_idx_val:]\n",
    "\n",
    "    # Separate images and annotations after splitting\n",
    "    train_images, train_annotations = zip(*train_data)\n",
    "    val_images, val_annotations = zip(*val_data)\n",
    "    test_images, test_annotations = zip(*test_data)\n",
    "\n",
    "# Move images to respective train/val folders\n",
    "if not only_test:\n",
    "    for img in train_images:\n",
    "        src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "        dest_path = os.path.join(train_output_folder, img[\"file_name\"])\n",
    "        shutil.move(src_path, dest_path)  # Move image to train folder\n",
    "\n",
    "    for img in val_images:\n",
    "        src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "        dest_path = os.path.join(val_output_folder, img[\"file_name\"])\n",
    "        shutil.move(src_path, dest_path)  # Move image to validation folder\n",
    "    \n",
    "for img in test_images:\n",
    "    src_path = os.path.join(output_frame_path, img[\"file_name\"])\n",
    "    dest_path = os.path.join(test_output_folder, img[\"file_name\"])\n",
    "    shutil.move(src_path, dest_path)  # Move image to validation folder\n",
    "\n",
    "# Create COCO-style JSONs for train and validation\n",
    "if not only_test:\n",
    "    train_json = {\n",
    "        \"licenses\": [],\n",
    "        \"info\": [],\n",
    "        \"images\": list(train_images),\n",
    "        \"annotations\": list(train_annotations),\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "    val_json = {\n",
    "        \"licenses\": [],\n",
    "        \"info\": [],\n",
    "        \"images\": list(val_images),\n",
    "        \"annotations\": list(val_annotations),\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "test_json = {\n",
    "    \"licenses\": [],\n",
    "    \"info\": [],\n",
    "    \"images\": list(test_images),\n",
    "    \"annotations\": list(test_annotations),\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "# Save train and validation JSON files\n",
    "if not only_test:\n",
    "    with open(train_annotation_combined, 'w+') as f:\n",
    "        json.dump(train_json, f, indent=4)\n",
    "\n",
    "    with open(val_annotation_combined, 'w+') as f:\n",
    "        json.dump(val_json, f, indent=4)\n",
    "    \n",
    "with open(test_annotation_combined, 'w+') as f:\n",
    "    json.dump(test_json, f, indent=4)\n",
    "\n",
    "print(f\"Processed {frame_counter} frames in total.\")\n",
    "if not only_test:\n",
    "    print(f\"Train: {len(train_images)} images, {len(train_annotations)} annotations\")\n",
    "    print(f\"Validation: {len(val_images)} images, {len(val_annotations)} annotations\")\n",
    "print(f\"Test: {len(test_images)} images, {len(test_annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "This code can be used to check if the annotations and frames have been matched correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import cv2\n",
    "\n",
    "# # Draw annotations on a frame\n",
    "# def draw_annotations(frame, annotations, categories):\n",
    "#     for ann in annotations:\n",
    "#         keypoints = ann.get(\"keypoints\", [])\n",
    "#         category_id = ann.get(\"category_id\", None)\n",
    "#         category_name = next((cat[\"name\"] for cat in categories if cat[\"id\"] == category_id), \"unknown\")\n",
    "        \n",
    "#         # Draw keypoints\n",
    "#         for i in range(0, len(keypoints), 3):\n",
    "#             x, y, v = keypoints[i:i+3]  # x, y, visibility\n",
    "#             if v > 0:  # Only draw visible keypoints\n",
    "#                 cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)  # Green keypoints\n",
    "\n",
    "#         # Optionally, draw lines (skeleton) if available\n",
    "#         skeleton = categories[0].get(\"skeleton\", [])\n",
    "#         for connection in skeleton:\n",
    "#             start_idx, end_idx = connection\n",
    "#             if start_idx < len(keypoints) // 3 and end_idx < len(keypoints) // 3:\n",
    "#                 x1, y1, v1 = keypoints[start_idx * 3:start_idx * 3 + 3]\n",
    "#                 x2, y2, v2 = keypoints[end_idx * 3:end_idx * 3 + 3]\n",
    "#                 if v1 > 0 and v2 > 0:  # Only draw lines between visible points\n",
    "#                     cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)  # Blue lines\n",
    "\n",
    "#     return frame\n",
    "\n",
    "# # Verify frames by drawing annotations\n",
    "# def verify_frames_with_annotations(images, annotations, frame_path, categories, num_verifications=5):\n",
    "#     print(\"\\n--- Verifying Frames with Annotations ---\")\n",
    "#     for _ in range(num_verifications):\n",
    "#         # Pick a random image\n",
    "#         image = random.choice(images)\n",
    "#         frame_file = os.path.join(frame_path, image[\"file_name\"])\n",
    "\n",
    "#         # Find associated annotations\n",
    "#         associated_annotations = [ann for ann in annotations if ann[\"image_id\"] == image[\"id\"]]\n",
    "\n",
    "#         print(f\"Verifying Frame: {image['file_name']}, ID: {image['id']}\")\n",
    "#         print(\"Annotations:\")\n",
    "#         for ann in associated_annotations:\n",
    "#             print(f\"  - ID: {ann['id']}, Keypoints: {ann['keypoints']}\")\n",
    "\n",
    "#         # Load and annotate the frame\n",
    "#         frame = cv2.imread(frame_file)\n",
    "#         if frame is not None:\n",
    "#             annotated_frame = draw_annotations(frame, associated_annotations, categories)\n",
    "\n",
    "#             # Display the annotated frame\n",
    "#             cv2.imshow(f\"Frame {image['id']} with Annotations\", annotated_frame)\n",
    "#             cv2.waitKey(0)  # Press any key to close the frame window\n",
    "#             cv2.destroyAllWindows()\n",
    "#         else:\n",
    "#             print(f\"Warning: Unable to load frame {frame_file}\")\n",
    "\n",
    "# # Call verification after processing all videos\n",
    "# verify_frames_with_annotations(\n",
    "#     combined_data[\"images\"], \n",
    "#     combined_data[\"annotations\"], \n",
    "#     output_frame_path, \n",
    "#     combined_data[\"categories\"]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
