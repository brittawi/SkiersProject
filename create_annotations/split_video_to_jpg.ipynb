{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat GPT code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the folder containing videos and output directories\n",
    "video_folder = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\test\\\\\"\n",
    "output_frame_path = \"C:\\\\awilde\\\\britta\\\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Frames_of_videos\\\\\"\n",
    "annotation_folder = \"C:\\\\awilde\\\\britta\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Annotations\\\\\"  # Folder with corresponding JSON files\n",
    "combined_json_path = \"C:\\\\awilde\\\\britta\\LTU\\\\SkiingProject\\\\SkiersProject\\\\Data\\\\Annotations\\\\combined_annotations.json\"\n",
    "\n",
    "# Maximum frame limits for specific videos (optional)\n",
    "frame_limits = {\n",
    "    \"DJI_0009.MP4\": 890\n",
    "}\n",
    "\n",
    "# Initialize counters\n",
    "frame_counter = 0\n",
    "combined_data = {\n",
    "    \"licenses\" : [],\n",
    "    \"info\" : [],\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the corresponding JSON filename\n",
    "def get_json_filename(video_name):\n",
    "    match = re.search(r'DJI_0*(\\d+)(_cut)?', video_name)\n",
    "    if match:\n",
    "        number = match.group(1).zfill(2)  # Extract the numeric part\n",
    "        suffix = match.group(2) if match.group(2) else \"\"  # Extract '_cut' if present\n",
    "        return f\"{number}{suffix}.json\"\n",
    "    return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\09.json\n",
      "14_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\14_cut.json\n",
      "15_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\15_cut.json\n",
      "17_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\17_cut.json\n",
      "18_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\18_cut.json\n",
      "22_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\22_cut.json\n",
      "25.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\25.json\n",
      "38.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\38.json\n",
      "40.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\40.json\n",
      "43.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\43.json\n",
      "44.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\44.json\n",
      "54_cut.json\n",
      "C:\\awilde\\britta\\LTU\\SkiingProject\\SkiersProject\\Data\\Annotations\\54_cut.json\n",
      "Processed 9082 frames in total.\n"
     ]
    }
   ],
   "source": [
    "image_id_counter = 1  # Start image IDs at 1\n",
    "annotation_id_counter = 1  # Start annotation IDs at 1\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.MP4'))]\n",
    "\n",
    "# Process each video and corresponding JSON\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    json_file_name = get_json_filename(video_file)\n",
    "    print(json_file_name)\n",
    "    #json_path = os.path.join(annotation_folder, f\"{os.path.splitext(video_file)[0]}_annotations.json\")\n",
    "    json_path = os.path.join(annotation_folder, json_file_name)\n",
    "    print(json_path)\n",
    "\n",
    "    # Check if the JSON file exists\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Warning: JSON file not found for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Split video into frames\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    current_frame = 0\n",
    "    max_frames = frame_limits.get(video_file, float('inf'))  # Default to no limit if not specified\n",
    "\n",
    "    while success and current_frame <= max_frames:\n",
    "        # Save frame with sequential numbering based on global frame_counter\n",
    "        frame_name = f\"frame_{frame_counter:06d}.jpg\"\n",
    "        save_path = os.path.join(output_frame_path, frame_name)\n",
    "        cv2.imwrite(save_path, image)\n",
    "\n",
    "        # Add to combined JSON\n",
    "        combined_data[\"images\"].append({\n",
    "            \"id\": image_id_counter,\n",
    "            \"width\": image.shape[1],\n",
    "            \"height\": image.shape[0],\n",
    "            \"file_name\": frame_name,\n",
    "            \"license\": 0,\n",
    "            \"flickr_url\": \"\",\n",
    "            \"coco_url\": \"\",\n",
    "            \"date_captured\": 0\n",
    "        })\n",
    "\n",
    "        success, image = vidcap.read()\n",
    "        frame_counter += 1\n",
    "        image_id_counter += 1  # Increment image ID counter\n",
    "        current_frame += 1\n",
    "\n",
    "    # Update JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        # Assign a sequential ID and link to the correct image\n",
    "        annotation[\"id\"] = annotation_id_counter\n",
    "        annotation[\"image_id\"] = annotation_id_counter  # Align with the correct frame ID\n",
    "        combined_data[\"annotations\"].append(annotation)\n",
    "        annotation_id_counter += 1\n",
    "\n",
    "    # Add categories only once (assumes they are consistent across files)\n",
    "    if not combined_data[\"categories\"]:\n",
    "        combined_data[\"categories\"] = data.get(\"categories\", [])\n",
    "\n",
    "# Save the combined JSON\n",
    "with open(combined_json_path, 'w') as f:\n",
    "    json.dump(combined_data, f, indent=4)\n",
    "\n",
    "print(f\"Processed {frame_counter} frames in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying Frames with Annotations ---\n",
      "Verifying Frame: frame_006212.jpg, ID: 6213\n",
      "Annotations:\n",
      "  - ID: 6213, Keypoints: [1046.16, 565.54, 1, 1049.73, 561.97, 1, 1042.6, 561.97, 1, 1055.07, 558.41, 1, 1037.25, 558.41, 1, 1066.35, 566.94, 1, 1028.76, 567.71, 1, 1078.92, 577.99, 1, 1014.25, 580.2, 1, 1081.25, 606.39, 1, 1006.6, 603.54, 1, 1062.2, 613.66, 1, 1039.03, 617.23, 1, 1083.59, 651.09, 1, 1040.82, 660.0, 1, 1104.98, 677.82, 1, 1044.38, 695.65, 1, 1046.16, 547.72, 1, 1046.16, 567.32, 1, 1049.73, 613.66, 1, 1117.46, 692.08, 1, 1043.98, 710.71, 1, 1119.24, 686.74, 1, 1040.03, 708.52, 1, 1103.2, 681.39, 1, 1047.95, 697.43, 1]\n",
      "Verifying Frame: frame_007709.jpg, ID: 7710\n",
      "Annotations:\n",
      "  - ID: 7710, Keypoints: [848.79, 575.99, 1, 850.45, 571.01, 1, 848.79, 571.01, 1, 860.41, 572.67, 1, 860.41, 572.67, 1, 869.73, 583.85, 1, 872.33, 577.47, 1, 884.25, 611.95, 1, 880.09, 603.41, 1, 881.99, 638.12, 1, 862.17, 603.51, 1, 905.72, 622.56, 1, 901.91, 620.8, 1, 884.47, 659.86, 1, 885.05, 655.1, 1, 903.97, 701.18, 1, 898.23, 690.7, 1, 853.77, 561.05, 1, 865.09, 577.55, 1, 903.57, 619.14, 1, 887.87, 710.58, 1, 879.33, 695.34, 1, 888.75, 713.54, 1, 881.55, 691.92, 1, 911.7, 708.92, 1, 902.29, 698.48, 1]\n",
      "Verifying Frame: frame_007608.jpg, ID: 7609\n",
      "Annotations:\n",
      "  - ID: 7609, Keypoints: [1196.7, 564.65, 1, 1200.55, 562.73, 1, 1196.7, 562.73, 1, 1210.16, 564.65, 1, 1210.16, 564.65, 1, 1219.04, 586.02, 1, 1211.93, 581.29, 1, 1213.4, 622.81, 1, 1197.72, 605.26, 1, 1183.42, 628.38, 1, 1186.47, 593.3, 1, 1206.91, 642.25, 1, 1209.83, 642.23, 1, 1184.05, 680.87, 1, 1209.67, 684.29, 1, 1179.41, 727.69, 1, 1212.08, 726.09, 1, 1208.23, 551.2, 1, 1211.68, 575.58, 1, 1208.93, 639.93, 1, 1161.31, 734.96, 1, 1189.66, 733.56, 1, 1161.33, 738.4, 1, 1190.58, 729.73, 1, 1184.45, 737.46, 1, 1216.82, 734.98, 1]\n",
      "Verifying Frame: frame_001073.jpg, ID: 1074\n",
      "Annotations:\n",
      "  - ID: 1074, Keypoints: [1210.42, 667.83, 1, 1210.42, 664.65, 1, 1208.83, 664.65, 1, 1199.27, 661.47, 1, 1204.05, 663.06, 1, 1193.1, 666.14, 1, 1188.41, 675.0, 1, 1204.74, 680.58, 1, 1197.18, 699.78, 1, 1226.14, 666.54, 1, 1215.2, 686.35, 1, 1178.16, 721.95, 1, 1182.05, 721.98, 1, 1186.33, 760.49, 1, 1191.21, 761.89, 1, 1182.16, 799.31, 1, 1169.02, 800.01, 1, 1207.23, 650.32, 1, 1196.49, 668.93, 1, 1180.16, 720.39, 1, 1201.66, 805.68, 1, 1184.34, 811.55, 1, 1201.26, 802.6, 1, 1181.75, 813.45, 1, 1176.98, 806.38, 1, 1163.05, 807.27, 1]\n",
      "Verifying Frame: frame_006499.jpg, ID: 6500\n",
      "Annotations:\n",
      "  - ID: 6500, Keypoints: [1344.34, 597.03, 1, 1352.13, 591.84, 1, 1339.14, 589.24, 1, 1357.33, 586.64, 1, 1328.75, 581.45, 1, 1365.12, 602.23, 1, 1305.38, 594.43, 1, 1378.11, 638.59, 1, 1274.21, 630.8, 1, 1380.7, 672.36, 1, 1287.19, 667.16, 1, 1331.35, 654.18, 1, 1297.58, 654.18, 1, 1344.34, 713.92, 1, 1320.96, 711.32, 1, 1343.07, 774.06, 1, 1321.36, 771.47, 1, 1349.53, 565.86, 1, 1339.14, 594.43, 1, 1315.77, 651.58, 1, 1353.69, 798.95, 1, 1324.96, 797.64, 1, 1357.33, 794.44, 1, 1317.77, 794.44, 1, 1335.68, 781.11, 1, 1323.76, 773.66, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "# Draw annotations on a frame\n",
    "def draw_annotations(frame, annotations, categories):\n",
    "    for ann in annotations:\n",
    "        keypoints = ann.get(\"keypoints\", [])\n",
    "        category_id = ann.get(\"category_id\", None)\n",
    "        category_name = next((cat[\"name\"] for cat in categories if cat[\"id\"] == category_id), \"unknown\")\n",
    "        \n",
    "        # Draw keypoints\n",
    "        for i in range(0, len(keypoints), 3):\n",
    "            x, y, v = keypoints[i:i+3]  # x, y, visibility\n",
    "            if v > 0:  # Only draw visible keypoints\n",
    "                cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)  # Green keypoints\n",
    "\n",
    "        # Optionally, draw lines (skeleton) if available\n",
    "        skeleton = categories[0].get(\"skeleton\", [])\n",
    "        for connection in skeleton:\n",
    "            start_idx, end_idx = connection\n",
    "            if start_idx < len(keypoints) // 3 and end_idx < len(keypoints) // 3:\n",
    "                x1, y1, v1 = keypoints[start_idx * 3:start_idx * 3 + 3]\n",
    "                x2, y2, v2 = keypoints[end_idx * 3:end_idx * 3 + 3]\n",
    "                if v1 > 0 and v2 > 0:  # Only draw lines between visible points\n",
    "                    cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)  # Blue lines\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Verify frames by drawing annotations\n",
    "def verify_frames_with_annotations(images, annotations, frame_path, categories, num_verifications=5):\n",
    "    print(\"\\n--- Verifying Frames with Annotations ---\")\n",
    "    for _ in range(num_verifications):\n",
    "        # Pick a random image\n",
    "        image = random.choice(images)\n",
    "        frame_file = os.path.join(frame_path, image[\"file_name\"])\n",
    "\n",
    "        # Find associated annotations\n",
    "        associated_annotations = [ann for ann in annotations if ann[\"image_id\"] == image[\"id\"]]\n",
    "\n",
    "        print(f\"Verifying Frame: {image['file_name']}, ID: {image['id']}\")\n",
    "        print(\"Annotations:\")\n",
    "        for ann in associated_annotations:\n",
    "            print(f\"  - ID: {ann['id']}, Keypoints: {ann['keypoints']}\")\n",
    "\n",
    "        # Load and annotate the frame\n",
    "        frame = cv2.imread(frame_file)\n",
    "        if frame is not None:\n",
    "            annotated_frame = draw_annotations(frame, associated_annotations, categories)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(f\"Frame {image['id']} with Annotations\", annotated_frame)\n",
    "            cv2.waitKey(0)  # Press any key to close the frame window\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            print(f\"Warning: Unable to load frame {frame_file}\")\n",
    "\n",
    "# Call verification after processing all videos\n",
    "verify_frames_with_annotations(\n",
    "    combined_data[\"images\"], \n",
    "    combined_data[\"annotations\"], \n",
    "    output_frame_path, \n",
    "    combined_data[\"categories\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
