{
  "batch_size": 8,
  "dropout": 0.2,
  "hidden_size": 128,
  "loss_type": "cross_entropy",
  "lr": 1e-05,
  "num_layers": 2
}